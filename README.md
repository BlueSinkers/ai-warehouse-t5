# Deliverable by 11/8
* Something very similar to what is in this repository. (https://github.com/alpersancili/Warehouse-Robot-Reinforcement-Learning-Project)
* I would like it to be larger than 3x3, and you can pick/choose the stack although Python+Gynasium feels good for this.
* Add obstacles, and learn how to disincentivize things like collision etc
* Giving negative feedback for it so the policy updates
* Perhaps implement with one or two agents, and add more complexity including a bay to bring back “objects” to. Feel free to use whatever stack you want, and this project is strictly 
* Eventually try and use SARSA and experiment with different approaches

## Project Description:
### Basic initial features: 
* We’ll define basic features based off of the first GitHub including (perhaps) a Move function (moving things around), Pick function (picking up things for certain purposes), and Deliver (letting go of things that are already picked up in specific places).
* Having at least 2 robots/agents learn to complete a workload of tasks, and using RL to optimize the routes, collisions (ensuring no collisions), and reducing travel time throughout.
* Track metrics of delivery/completion of tasks including average delivery time, throughput, workload balance, and other metrics.

### Bonus Features: 
* Dynamic task generation, more complex layouts, multiple robots, coordination mechanisms to avoid deadlocks or collisions, and using more other complicated Deep Learning approaches.                              
